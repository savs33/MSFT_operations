{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "import math\n",
    "#from __future__ import division\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import  tree, linear_model\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import datetime as dt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/v-savrav/Desktop/30/InvociePrediction30days_02Oct2019_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ReceiptDate', 'FirstPOCAssignmentDate', 'LastBusinessUserDate',\n",
    "        'Doc. Date',\n",
    "       'Clrng doc.', 'Pmnt date', 'Reference',\n",
    "       'Clearing', 'Pstng Date', 'CoCd', 'Net due dt', 'Year',\n",
    "       'Year/month', 'Period', \n",
    "       'Bline Date', 'Reference Key', 'Entry Date', 'SubmitDate'\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Region', 'Frequency', 'CC', 'received_days',\n",
       "       'processing_days', 'days_to_approval', 'days_to_be_cleared', 'PaidDays',\n",
       "       'NewPaymentTerm', 'DocumentNo', 'Type', 'Amount in doc. curr.', 'Curr.',\n",
       "       'Vendor', 'Discount base amount', 'Discount amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df[['CC','received_days','processing_days','days_to_approval','days_to_be_cleared',\n",
    " #      'Vendor',  'NewPaymentTerm', 'Amount in doc. curr.',\n",
    "  #     'Curr.', 'Type',  'Discount amount',\n",
    "   #    'Discount base amount', 'Country', 'Region', 'Frequency']]\n",
    "\n",
    "#Modified by Zaheer\n",
    "X=df[['CC','received_days','processing_days','days_to_approval','days_to_be_cleared'\n",
    "      ,'Vendor',\n",
    "       'NewPaymentTerm', 'Amount in doc. curr.','Curr.','Type',  \n",
    "            'Discount amount','DocumentNo', 'Discount base amount','Country',\n",
    "       'Region', 'Frequency']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-savrav\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  preprocessing # used for label encoding and imputing NaNs\n",
    "\n",
    "# One-hot encode the data using pandas get_dummies\n",
    "X.fillna(0,inplace=True)\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X[c].values)) \n",
    "        X[c] = lbl.transform(list(X[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56245"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "def model_prediction(X_train, X_test,y_train, y_test,model_name):\n",
    "    \n",
    "    xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                               colsample_bytree=1, max_depth=7)\n",
    "    params = {'n_estimators': 500, 'max_depth': 6, 'min_samples_split': 4,\n",
    "          'learning_rate': 0.05, 'loss': 'ls'}\n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "    xgb.fit(X_train,y_train)\n",
    "    clf.fit(X_train,y_train)\n",
    "    filename = 'C:/Users/v-savrav/Desktop/30/models/' + model_name+'_model.sav'\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    filename1 ='C:/Users/v-savrav/Desktop/30/models/' + model_name+'_model1.sav'\n",
    "    pickle.dump(xgb, open(filename1, 'wb'))\n",
    "    pred1 = xgb.predict(X_test)\n",
    "    pred2 = clf.predict(X_test)\n",
    "    finalpred =(pred1+pred2)/2\n",
    "    mae = mean_absolute_error(finalpred ,y_test)\n",
    "    return finalpred,y_test,mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paid days Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['var_paymenent_days'] = df['PaidDays'] - df['NewPaymentTerm'] \n",
    "target=df['PaidDays']\n",
    "y_train, y_test = train_test_split(target, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-savrav\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:43:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "paid_days_prediction,actual_paid,mae= model_prediction(X_train, X_test,y_train, y_test,'stage4_paid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4901482545323999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 26     47427\n",
       " 29     37735\n",
       " 28     26195\n",
       " 27     25611\n",
       " 25      9180\n",
       " 24      8533\n",
       " 22      5655\n",
       " 23      4825\n",
       " 21      4180\n",
       " 30      2858\n",
       " 20      2513\n",
       " 12      2434\n",
       " 14      2371\n",
       " 1       2305\n",
       " 10      2130\n",
       " 7       2102\n",
       " 15      2020\n",
       " 19      2017\n",
       " 13      1933\n",
       " 18      1871\n",
       " 11      1870\n",
       " 6       1823\n",
       " 2       1712\n",
       " 31      1659\n",
       " 8       1570\n",
       " 3       1563\n",
       " 17      1535\n",
       " 9       1496\n",
       " 4       1477\n",
       " 32      1439\n",
       "        ...  \n",
       " 57       241\n",
       " 54       224\n",
       " 53       206\n",
       " 52       205\n",
       " 51       189\n",
       " 58       150\n",
       " 60       144\n",
       " 59       137\n",
       " 0        125\n",
       "-1          6\n",
       "-2          4\n",
       "-4          4\n",
       "-6          2\n",
       "-29         2\n",
       "-11         1\n",
       "-3          1\n",
       "-5          1\n",
       "-7          1\n",
       "-8          1\n",
       "-10         1\n",
       "-108        1\n",
       "-13         1\n",
       "-238        1\n",
       "-16         1\n",
       "-26         1\n",
       "-30         1\n",
       "-35         1\n",
       "-65         1\n",
       "-106        1\n",
       "-142        1\n",
       "Name: PaidDays, Length: 82, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PaidDays'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel('C:/Users/v-savrav/Desktop/30/Data_test/Stage4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "paiddf = pd.DataFrame({'Paid - Act':actual_paid, 'Paid - Pr':paid_days_prediction})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([paiddf, X_test],axis=1)\n",
    "final['stage']='stage4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_excel('C:\\\\Users\\\\v-savrav\\\\Desktop\\\\30\\\\Train_results\\\\stage4_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns #Added by Zaheer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added by Zaheer\n",
    "ff=final.rename(columns={'Amount in doc. curr.':'Amount',\n",
    "             'NewPaymentTerm':'Pay Term'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added by Zaheer and removed columns (,'Rcvd -Act','Rcvd  -Pr','Procesing - Act',\n",
    "##'Procesing  - Pr''Approval - Act','Approval - Pr',)\n",
    "final = ff[['DocumentNo','Paid - Act','Paid - Pr','CC','Vendor',\n",
    "'Pay Term','Amount','Curr.','Type','Discount amount','Country','Region','Frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added by Zaheer\n",
    "final['stage']='stage4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage4=final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stage4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage4.to_excel('C:/Users/v-shzah/Documents/Ganesh Data/Train - All Payment Terms Output Files/stage4_Train.xlsx')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Writing the Output to Data Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc \n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=azgovprdsql11;'\n",
    "                      'Database=PWT;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in stage4.iterrows():\n",
    "    cursor.execute('''INSERT INTO [All_Payment_Term_Train_Stage4_Output]\n",
    "                   (\n",
    "                  [DocumentNo],\n",
    "                  [Paid - Act],[Paid - Pr],\n",
    "                  [CC],[Vendor],[Pay Term],[Amount],[Curr.],[Type],\n",
    "                  [Discount amount],[Country],[Region],[Frequency],[stage] )\n",
    "                   \n",
    "    values (?,?,?,?, ?,?,?,?, ?,?,?,?, ?,?)''',\n",
    "    row['DocumentNo'],row['Paid - Act'],row['Paid - Pr'],\n",
    "                      row['CC'],row['Vendor'],row['Pay Term'],row['Amount'],row['Curr.'],\n",
    "                      row['Type'],row['Discount amount'],row['Country'],row['Region'],\n",
    "                      row['Frequency'],row['stage'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
